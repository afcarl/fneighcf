# fneighcf

Python implementation of the collaborative filtering algorithm for explicit feedback data described in Koren, Y. (2010). Factor in the neighbors: Scalable and accurate collaborative filtering. ACM Transactions on Knowledge Discovery from Data (TKDD), 4(1), 1.

The paper (Factor in the neighbors: Scalable and accurate collaborative filtering) can be downloaded here:
[http://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/a1-koren.pdf](http://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/a1-koren.pdf)

## Basic model
The model consist of predicting the rating that a user would give to an item by parameterizing how much a deviation from average in each rated item translates into a higher or lower rating for the item to predict. The basic formula is as follows:

```rating_ui = global_bias + user_bias_u + item_bias_i + sum( (rating_i – bias_uj )*w_ij ) + sum(c_ij)```

(Where ‘U’ is a given user, ‘I’ is the item to predict, and ‘J’ are all the items rated by the user. More details can be found in the paper above).

While rating predictions from this model usually don’t achieve as low RMSE as those generated by matrix factorization models, they allow for immediate update of recommendations as soon as the user submits feedback for more items without updating the model itself, and can also start recommending to new users as soon as they rate items.

## Instalation
Package is available on PyPI, can be installed with

```pip install fneighcf```

## Usage
```
import pandas as pd
from fneighcf import FNeigh
ratings = pd.DataFrame([(1,1,5),(1,2,1),(1,3,4),(2,1,3),(2,2,4),(3,2,1),(3,3,2)], columns=[‘UserId’,’ItemId’,’Rating’])
rec = FNeigh(norm_nratings=-.5, reg_param_biases=1e-3, reg_param_interactions=1)
rec.fit(ratings, maxiter=10, step_size_biases=1e-3, step_size_interactions=0.05)
rec.predict(user=1, item=1)
rec.top_n_saved(n=10, user=1)
rec.top_n(pd.DataFrame(rating_history=[(1,5),(2,4),(3,1),(4,1)],columns=[‘ItemId’,’Rating’]), n=10, user=1)
rec.top_n([], n=10, user=None)
```
Note that the regularization parameters and step sizes used can make a huge difference in the estimated model. I’d recommend tracking the RMSE after each update (```verbose=True``` as argument to fit) with the default parameters and playing with them if it doesn’t behave as expected.

A more detailed example with the MovieLens data can be found [in this IPython notebook](http://nbviewer.jupyter.org/github/david-cortes/fneighcf/blob/master/example/fneighcf_example.ipynb), and docstrings are available for internal documentation (e.g. ```?FNeight.fit```).

## Implementation Notes
This is a pure python implementation of the algorithm, so fitting the model will be slow for large datasets. The code quality is research-grade. As a point of reference, one gradient descent iteration over the movielens-100k takes around 5 minutes on a regular computer, while an iteration over the movielens-1M takes around 1 hour. Making recommendations from the model is fast though.

User and item biases are started with a simple heuristic:
```
Residual_rating1 = Rating – mean(Ratings)
User_bias = mean(Residual_rating1_user)
Residual_rating2 = Residual_rating1 - User_bias
Item_bias = mean(Residual_rating2_item)
```
They can be left like that if a step size equal to zero is specified for biases in the fit method.

The package has only been tested under Python 3.

## Some comments
Although this kind of model is able to make recommendations to any new user with ratings, be aware that it cannot recommend new items.

While the idea behind the model is very sound and it achieves somewhat low RMSE, in practice, Top-N recommendations from this model tend to be all too similar for all users, and for smaller datasets they will most likely end up being recommendations by item popularity. It can nevertheless serve as a useful comparison point and to do research on the topic.

## References
* Koren, Y. (2010). Factor in the neighbors: Scalable and accurate collaborative filtering. ACM Transactions on Knowledge Discovery from Data (TKDD), 4(1), 1.
