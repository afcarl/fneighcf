{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage of fneighcf\n",
    "\n",
    "This Ipython notebook illustrates the usage of the [fneighcf](https://github.com/david-cortes/fneighcf) package on the [MovieLens 1M dataset](https://grouplens.org/datasets/movielens/1m/).\n",
    "\n",
    "[fneighcf](https://github.com/david-cortes/fneighcf) is a Python implementation of the collaborative filtering algorithm described in _Koren, Y. (2010). Factor in the neighbors: Scalable and accurate collaborative filtering. ACM Transactions on Knowledge Discovery from Data (TKDD), 4(1), 1._, using Cython for fast computations.\n",
    "\n",
    "** Small note: if the TOC here is not clickable or the math symbols don't show properly, try visualizing this same notebook from nbviewer following [this link](http://nbviewer.jupyter.org/github/david-cortes/cmfrec/blob/master/example/cmfrec_movielens_sideinfo.ipynb). **\n",
    "** *\n",
    "## Sections\n",
    "* [1. Model description](#p1)\n",
    "* [2. Preparing the data](#p2)\n",
    "* [3. Fitting the model](#p3)\n",
    "* [4. Evaluating predictions](#p4)\n",
    "* [5. Examining some recomendations](#p5)\n",
    "* [6. References](#p6)\n",
    "** *\n",
    "<a id=\"p1\"></a>\n",
    "## 1. Model description\n",
    "\n",
    "The model consists of predicting the rating that each user gave to each movie according to parameterized item-item effects, considering both the ratings themselves but also the items that were rated as a form of implicit feedback. Having a parameterized model makes recommendations a lot faster and more scalable than typical user-user or item-item nearest-neighbor search, as well as increasing recomendation quality.\n",
    "\n",
    "Here, ratings are predicted as follows:\n",
    "\n",
    "$$\n",
    "\\hat{r_{ui}} = \\mu + b_u + b_i + |R_u|^{-\\alpha} (\\sum_{j \\in R_u} (r_{uj} - \\mu - b_u' - b_i')W_{ij}  + \\sum_{j \\in R_u} C_{ij})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "* $r_{ui}$ is the rating from user $u$ to item $i$.\n",
    "* $\\mu$ is the average rating across all data.\n",
    "* $b_u$ is the bias for user $u$ (part of model parameters).\n",
    "* $b_i$ is the bias for item $i$ (part of model parameters).\n",
    "* $R_u$ is the set of items rated by user $u$.\n",
    "* $\\alpha$ is a hyperparameter to control the effect from ratings.\n",
    "* $b_u'$ and $b_i'$ are fixed user and item biases (not part of model parameters) calculated through a simple heuristic.\n",
    "* $W$ is a square matrix $(N_{items} \\:x \\:N_{items})$ that parameterizes the effect of rating deviations from each item on the rating each other item.\n",
    "* $C$ is a square matrix $(N_{items} \\:x \\:N_{items})$ that parameterizes the implicit effects of rating an item (regardless of the rating given) on the rating given to every other item.\n",
    "\n",
    "Regularization is applied to the squared $l_2$ norm of all parameters and to the calculation of the fixed biases.\n",
    "\n",
    "\n",
    "Note that this model requires storing dense matrices of size $(N_{items} \\:x \\:N_{items})$, and in a typical setting, has millions of parameters. Other models proposed in the paper above with less space requirement but more computation requirements are not implemented here.\n",
    "\n",
    "** *\n",
    "<a id=\"p2\"></a>\n",
    "## 2. Preparing the data\n",
    "\n",
    "\n",
    "Loading the [Movielens-100k dataset](https://grouplens.org/datasets/movielens/100k/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2001-01-06 23:37:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>2001-01-06 23:39:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:29:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:12:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>527</td>\n",
       "      <td>5</td>\n",
       "      <td>2001-01-06 23:36:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId  ItemId  Rating           Timestamp\n",
       "0       1       1       5 2001-01-06 23:37:48\n",
       "1       1      48       5 2001-01-06 23:39:11\n",
       "2       1     150       5 2000-12-31 22:29:37\n",
       "3       1     260       4 2000-12-31 22:12:40\n",
       "4       1     527       5 2001-01-06 23:36:35"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, time, re\n",
    "from datetime import datetime\n",
    "\n",
    "ratings=pd.read_table('~/ml-1m/ratings.dat',sep='::',engine='python',names=['UserId','ItemId','Rating','Timestamp'])\n",
    "ratings['Timestamp']=ratings.Timestamp.map(lambda x: datetime(*time.localtime(x)[:6])).map(lambda x: pd.to_datetime(x))\n",
    "ratings=ratings.sort_values(['UserId','ItemId']).reset_index(drop=True)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a temporal train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(972815, 4)\n",
      "(27102, 4)\n"
     ]
    }
   ],
   "source": [
    "time_cutoff='2002-01-01'\n",
    "train=ratings.loc[ratings.Timestamp<=time_cutoff]\n",
    "test=ratings.loc[ratings.Timestamp>time_cutoff]\n",
    "users_train=set(list(train.UserId))\n",
    "items_train=set(list(train.ItemId))\n",
    "test=test.loc[test.UserId.map(lambda x: x in users_train)]\n",
    "test=test.loc[test.ItemId.map(lambda x: x in items_train)]\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading movie titles to inspect recomendations later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles=pd.read_table('~/ml-1m/movies.dat',sep='::',engine='python',header=None)\n",
    "movie_titles.columns=['ItemId','title','genres']\n",
    "movie_titles=movie_titles[['ItemId','title']]\n",
    "\n",
    "movie_id_to_title={i.ItemId:i.title for i in movie_titles.itertuples()}\n",
    "\n",
    "# function to print recommended lists more nicely\n",
    "def print_reclist(reclist):\n",
    "    list_w_info=[str(m+1)+\") - \"+movie_id_to_title[reclist[m]]+\\\n",
    "        \" - Average Rating: \"+str(np.round(avg_movie_rating[reclist[m]],2))+\\\n",
    "        \" - Number of ratings: \"+str(num_ratings_per_movie[reclist[m]]) for m in range(len(reclist))]\n",
    "    print(\"\\n\".join(list_w_info))\n",
    "    \n",
    "# aggregate statistics\n",
    "avg_movie_rating=train.groupby('ItemId')['Rating'].mean()\n",
    "num_ratings_per_movie=train.groupby('ItemId')['Rating'].agg(lambda x: len(tuple(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** *\n",
    "<a id=\"p3\"></a>\n",
    "## 3. Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 40s, sys: 24.6 s, total: 21min 5s\n",
      "Wall time: 21min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from fneighcf import FNeigh\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "rec = FNeigh(center_ratings=True, alpha=0.5, lambda_bu=10, lambda_bi=25,\n",
    "             lambda_u=5e-1, lambda_i=5e-2, lambda_W=5e-3, lambda_C=5e-2)\n",
    "\n",
    "# The better-quality alternative\n",
    "# With this dataset it takes 9GB of RAM\n",
    "rec.fit(train, method='lbfgs', opts_lbfgs={'maxiter':300, 'disp':True})\n",
    "\n",
    "# A faster alternative, uses 0.7GB of RAM and takes 8 minutes\n",
    "# However, the solution it reaches is not as good\n",
    "# rec.fit(train, method='sgd', epochs=100, step_size=1e-3, early_stop=False, verbose=True)\n",
    "\n",
    "# Note that the model has 27 million parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** *\n",
    "<a id=\"p4\"></a>\n",
    "## 4. Evaluating predictions\n",
    "\n",
    "Making predictions on the test set - predicting like this requires passing `save_data=True` to the fit method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84 ms, sys: 4 ms, total: 88 ms\n",
      "Wall time: 86.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test['Predicted']=rec.predict(uids=test.UserId, iids=test.ItemId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE (root mean squared error):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0514003487805468"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean((test.Predicted-test.Rating)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How users would have rated top and bottom predictions, and comparison against a non-personalized recommended list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averge movie rating: 3.5696247441040905\n",
      "Average rating for top-10 rated by each user: 4.353635798632691\n",
      "Average rating for bottom-10 rated by each user: 2.6254402320281747\n",
      "Average rating for top-10 recommendations of best-rated movies: 3.9181686347627926\n",
      "----------------------\n",
      "Average rating for top-10 recommendations from this model: 3.8479386782680756\n",
      "Average rating for bottom-10 (non-)recommendations from this model: 3.172570955044541\n"
     ]
    }
   ],
   "source": [
    "avg_ratings=train.groupby('ItemId')['Rating'].mean().to_frame().rename(columns={\"Rating\":\"AvgRating\"})\n",
    "test2=pd.merge(test,avg_ratings,left_on='ItemId',right_index=True,how='left')\n",
    "\n",
    "print('Averge movie rating:',test2.groupby('UserId')['Rating'].mean().mean())\n",
    "print('Average rating for top-10 rated by each user:',test2.sort_values(['UserId','Rating'],ascending=False).groupby('UserId')['Rating'].head(10).mean())\n",
    "print('Average rating for bottom-10 rated by each user:',test2.sort_values(['UserId','Rating'],ascending=True).groupby('UserId')['Rating'].head(10).mean())\n",
    "print('Average rating for top-10 recommendations of best-rated movies:',test2.sort_values(['UserId','AvgRating'],ascending=False).groupby('UserId')['Rating'].head(10).mean())\n",
    "print('----------------------')\n",
    "print('Average rating for top-10 recommendations from this model:',test2.sort_values(['UserId','Predicted'],ascending=False).groupby('UserId')['Rating'].head(10).mean())\n",
    "print('Average rating for bottom-10 (non-)recommendations from this model:',test2.sort_values(['UserId','Predicted'],ascending=True).groupby('UserId')['Rating'].head(10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** *\n",
    "<a id=\"p5\"></a>\n",
    "## 5. Examining some recomendations\n",
    "\n",
    "Now examining top recommended lists for some random users.\n",
    "\n",
    "Generating a top-N list for a user from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 1.05 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1326, 1755, 3936,   71, 2535, 3901, 2938, 1824, 3870, 3736, 2937,\n",
       "       2904, 2210, 2204, 2203, 1940, 1936, 1935, 1596, 1507])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rec.topN(uid=1, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 2.94 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3593,  810, 2383, 2555, 2817, 2799, 1556, 2643,  546, 3268, 3799,\n",
       "       2382,  181, 1389,   66, 1760, 1381, 1998, 2816, 2153])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rec.topN(items=[1, 48, 150, 260, 527], ratings=[1, 3, 4, 4, 2], n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now checking some top-10 recommended lists in details for some users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings from User 1:  53\n",
      "\n",
      "Recomendations from this model\n",
      "1) - Amityville II: The Possession (1982) - Average Rating: 2.13 - Number of ratings: 55\n",
      "2) - Shooting Fish (1997) - Average Rating: 3.55 - Number of ratings: 29\n",
      "3) - Phantom of the Opera, The (1943) - Average Rating: 3.73 - Number of ratings: 110\n",
      "4) - Fair Game (1995) - Average Rating: 2.13 - Number of ratings: 94\n",
      "5) - Earthquake (1974) - Average Rating: 2.85 - Number of ratings: 117\n",
      "6) - Duets (2000) - Average Rating: 2.65 - Number of ratings: 95\n",
      "7) - Man Facing Southeast (Hombre Mirando al Sudeste) (1986) - Average Rating: 3.7 - Number of ratings: 30\n",
      "8) - Homegrown (1998) - Average Rating: 3.36 - Number of ratings: 102\n",
      "9) - Our Town (1940) - Average Rating: 3.81 - Number of ratings: 47\n",
      "10) - Big Carnival, The (1951) - Average Rating: 3.76 - Number of ratings: 37\n"
     ]
    }
   ],
   "source": [
    "reclist_user1 = rec.topN(uid=1, n=10)\n",
    "reclist_user100 = rec.topN(uid=100, n=10)\n",
    "\n",
    "print('Number of ratings from User 1: ',train.loc[train.UserId==1].shape[0])\n",
    "print('')\n",
    "print('Recomendations from this model')\n",
    "print_reclist(reclist_user1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings from User 100:  76\n",
      "\n",
      "Recomendations from this model\n",
      "1) - Five Wives, Three Secretaries and Me (1998) - Average Rating: 4.0 - Number of ratings: 1\n",
      "2) - Nueba Yol (1995) - Average Rating: 1.0 - Number of ratings: 1\n",
      "3) - Specials, The (2000) - Average Rating: 4.33 - Number of ratings: 3\n",
      "4) - Death in the Garden (Mort en ce jardin, La) (1956) - Average Rating: 3.0 - Number of ratings: 3\n",
      "5) - Hillbillys in a Haunted House (1967) - Average Rating: 1.0 - Number of ratings: 1\n",
      "6) - It Happened Here (1961) - Average Rating: 3.0 - Number of ratings: 2\n",
      "7) - Zero Kelvin (Kj�rlighetens kj�tere) (1995) - Average Rating: 4.0 - Number of ratings: 1\n",
      "8) - Lotto Land (1995) - Average Rating: 1.0 - Number of ratings: 1\n",
      "9) - I'll Never Forget What's 'is Name (1967) - Average Rating: 3.0 - Number of ratings: 1\n",
      "10) - Another Man's Poison (1952) - Average Rating: 4.0 - Number of ratings: 1\n"
     ]
    }
   ],
   "source": [
    "print('Number of ratings from User 100: ',train.loc[train.UserId==100].shape[0])\n",
    "print('')\n",
    "print('Recomendations from this model')\n",
    "print_reclist(reclist_user100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the model seems to make more risky (less common items) recomendations the more ratings a user has, which might be a good thing if increased personalization is desired.\n",
    "** *\n",
    "<a id=\"p6\"></a>\n",
    "## 6. References\n",
    "* Koren, Y. (2010). Factor in the neighbors: Scalable and accurate collaborative filtering. ACM Transactions on Knowledge Discovery from Data (TKDD), 4(1), 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
